{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8cd75f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/100.3 kB ? eta -:--:--\n",
      "     ------------------------------------ 100.3/100.3 kB 968.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\kong jiyun\\appdata\\roaming\\python\\python38\\site-packages (from scikit-optimize) (1.2.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\anaconda3\\envs\\deepvm\\lib\\site-packages (from scikit-optimize) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\anaconda3\\envs\\deepvm\\lib\\site-packages (from scikit-optimize) (1.24.4)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kong jiyun\\appdata\\roaming\\python\\python38\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\anaconda3\\envs\\deepvm\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\envs\\deepvm\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-23.12.0 scikit-optimize-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d39e8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "seed_everything()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89333f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocessed_csv/train_preprocessed.csv')\n",
    "test = pd.read_csv('preprocessed_csv/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c4322ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['com_reg_ver_win_rate', 'ver_win_rate_x', 'ver_win_ratio_per_bu']] = train[['com_reg_ver_win_rate', 'ver_win_rate_x', 'ver_win_ratio_per_bu']].replace(np.nan, 0)\n",
    "test[['com_reg_ver_win_rate', 'ver_win_rate_x', 'ver_win_ratio_per_bu']] = test[['com_reg_ver_win_rate', 'ver_win_rate_x', 'ver_win_ratio_per_bu']].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8090a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(train, test):\n",
    "    categorical_columns = train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(train[col])\n",
    "        train[col] = le.transform(train[col])\n",
    "        \n",
    "        for label in np.unique(test[col]):\n",
    "            if label not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, label)\n",
    "        test[col] = le.transform(test[col])\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train, test = encode_categorical_variables(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eea612ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='is_converted', axis=1)\n",
    "y = train['is_converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d2b35",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "977019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_score(clf, X, y, n_fold):\n",
    "    X, y = X.values, y.values\n",
    "    strat_kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    roc_auc_list = []\n",
    "\n",
    "    for train_index, test_index in strat_kfold.split(X, y):\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        clf.fit(x_train_fold, y_train_fold)\n",
    "        preds = clf.predict(x_test_fold)\n",
    "        roc_auc_test = roc_auc_score(y_test_fold, preds)\n",
    "        roc_auc_list.append(roc_auc_test)\n",
    "\n",
    "    return np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f3feec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_params_rf(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    params = {\n",
    "        'n_estimators' : int(n_estimators),\n",
    "        'max_depth' : int(max_depth),\n",
    "        'min_samples_split' : int(min_samples_split),\n",
    "        'min_samples_leaf' : int(min_samples_leaf),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    clf = DecisionTreeClassifier(**params)\n",
    "    return stratified_kfold_score(clf, X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ef13f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9761   \u001b[0m | \u001b[0m43.71    \u001b[0m | \u001b[0m47.59    \u001b[0m | \u001b[0m73.74    \u001b[0m | \u001b[0m638.8    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.9817   \u001b[0m | \u001b[95m24.04    \u001b[0m | \u001b[95m8.644    \u001b[0m | \u001b[95m7.692    \u001b[0m | \u001b[95m879.6    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m24.02    \u001b[0m | \u001b[0m14.21    \u001b[0m | \u001b[0m11.79    \u001b[0m | \u001b[0m878.6    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.985    \u001b[0m | \u001b[95m26.45    \u001b[0m | \u001b[95m1.937    \u001b[0m | \u001b[95m14.74    \u001b[0m | \u001b[95m902.4    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9818   \u001b[0m | \u001b[0m10.4     \u001b[0m | \u001b[0m2.978    \u001b[0m | \u001b[0m47.71    \u001b[0m | \u001b[0m416.9    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9767   \u001b[0m | \u001b[0m97.37    \u001b[0m | \u001b[0m35.77    \u001b[0m | \u001b[0m99.4     \u001b[0m | \u001b[0m436.5    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9839   \u001b[0m | \u001b[0m24.41    \u001b[0m | \u001b[0m1.121    \u001b[0m | \u001b[0m19.32    \u001b[0m | \u001b[0m900.2    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9814   \u001b[0m | \u001b[0m47.92    \u001b[0m | \u001b[0m10.63    \u001b[0m | \u001b[0m13.45    \u001b[0m | \u001b[0m921.9    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9821   \u001b[0m | \u001b[0m19.81    \u001b[0m | \u001b[0m9.215    \u001b[0m | \u001b[0m7.652    \u001b[0m | \u001b[0m914.5    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9821   \u001b[0m | \u001b[0m45.82    \u001b[0m | \u001b[0m7.788    \u001b[0m | \u001b[0m15.36    \u001b[0m | \u001b[0m894.6    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9811   \u001b[0m | \u001b[0m11.91    \u001b[0m | \u001b[0m7.4      \u001b[0m | \u001b[0m23.09    \u001b[0m | \u001b[0m385.6    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9824   \u001b[0m | \u001b[0m10.5     \u001b[0m | \u001b[0m2.292    \u001b[0m | \u001b[0m4.753    \u001b[0m | \u001b[0m900.9    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.981    \u001b[0m | \u001b[0m13.93    \u001b[0m | \u001b[0m10.31    \u001b[0m | \u001b[0m37.9     \u001b[0m | \u001b[0m456.2    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9812   \u001b[0m | \u001b[0m12.73    \u001b[0m | \u001b[0m3.858    \u001b[0m | \u001b[0m78.88    \u001b[0m | \u001b[0m400.8    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9829   \u001b[0m | \u001b[0m23.97    \u001b[0m | \u001b[0m1.313    \u001b[0m | \u001b[0m34.87    \u001b[0m | \u001b[0m924.3    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m32.33    \u001b[0m | \u001b[0m7.777    \u001b[0m | \u001b[0m53.23    \u001b[0m | \u001b[0m940.9    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9841   \u001b[0m | \u001b[0m33.4     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m19.22    \u001b[0m | \u001b[0m910.8    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9765   \u001b[0m | \u001b[0m43.04    \u001b[0m | \u001b[0m41.86    \u001b[0m | \u001b[0m83.99    \u001b[0m | \u001b[0m101.6    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9816   \u001b[0m | \u001b[0m97.62    \u001b[0m | \u001b[0m12.68    \u001b[0m | \u001b[0m14.07    \u001b[0m | \u001b[0m263.0    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9805   \u001b[0m | \u001b[0m83.48    \u001b[0m | \u001b[0m11.37    \u001b[0m | \u001b[0m62.34    \u001b[0m | \u001b[0m253.3    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9766   \u001b[0m | \u001b[0m83.44    \u001b[0m | \u001b[0m42.38    \u001b[0m | \u001b[0m11.56    \u001b[0m | \u001b[0m298.4    \u001b[0m |\n",
      "| \u001b[95m22       \u001b[0m | \u001b[95m0.9857   \u001b[0m | \u001b[95m77.33    \u001b[0m | \u001b[95m2.995    \u001b[0m | \u001b[95m3.127    \u001b[0m | \u001b[95m224.5    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.9822   \u001b[0m | \u001b[0m95.23    \u001b[0m | \u001b[0m7.719    \u001b[0m | \u001b[0m6.003    \u001b[0m | \u001b[0m216.4    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.9838   \u001b[0m | \u001b[0m58.03    \u001b[0m | \u001b[0m5.948    \u001b[0m | \u001b[0m7.789    \u001b[0m | \u001b[0m220.3    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m64.33    \u001b[0m | \u001b[0m7.566    \u001b[0m | \u001b[0m8.089    \u001b[0m | \u001b[0m243.9    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.9784   \u001b[0m | \u001b[0m72.52    \u001b[0m | \u001b[0m27.81    \u001b[0m | \u001b[0m9.977    \u001b[0m | \u001b[0m214.7    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.9839   \u001b[0m | \u001b[0m87.54    \u001b[0m | \u001b[0m4.917    \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m242.1    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.9844   \u001b[0m | \u001b[0m26.92    \u001b[0m | \u001b[0m1.322    \u001b[0m | \u001b[0m19.62    \u001b[0m | \u001b[0m226.9    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.9832   \u001b[0m | \u001b[0m21.83    \u001b[0m | \u001b[0m5.299    \u001b[0m | \u001b[0m14.82    \u001b[0m | \u001b[0m202.0    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.9826   \u001b[0m | \u001b[0m29.44    \u001b[0m | \u001b[0m2.429    \u001b[0m | \u001b[0m40.89    \u001b[0m | \u001b[0m217.9    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.98     \u001b[0m | \u001b[0m17.48    \u001b[0m | \u001b[0m17.29    \u001b[0m | \u001b[0m13.37    \u001b[0m | \u001b[0m240.9    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.9844   \u001b[0m | \u001b[0m75.77    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m19.34    \u001b[0m | \u001b[0m226.5    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.9821   \u001b[0m | \u001b[0m10.99    \u001b[0m | \u001b[0m1.657    \u001b[0m | \u001b[0m21.92    \u001b[0m | \u001b[0m167.0    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.9847   \u001b[0m | \u001b[0m38.18    \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m17.9     \u001b[0m | \u001b[0m207.2    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m43.96    \u001b[0m | \u001b[0m3.279    \u001b[0m | \u001b[0m36.94    \u001b[0m | \u001b[0m171.3    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.9838   \u001b[0m | \u001b[0m51.31    \u001b[0m | \u001b[0m5.599    \u001b[0m | \u001b[0m2.449    \u001b[0m | \u001b[0m184.3    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.9856   \u001b[0m | \u001b[0m54.32    \u001b[0m | \u001b[0m1.752    \u001b[0m | \u001b[0m4.254    \u001b[0m | \u001b[0m144.1    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.9791   \u001b[0m | \u001b[0m56.75    \u001b[0m | \u001b[0m26.35    \u001b[0m | \u001b[0m5.981    \u001b[0m | \u001b[0m144.7    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.9842   \u001b[0m | \u001b[0m58.91    \u001b[0m | \u001b[0m1.338    \u001b[0m | \u001b[0m24.34    \u001b[0m | \u001b[0m144.5    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.9848   \u001b[0m | \u001b[0m43.79    \u001b[0m | \u001b[0m1.083    \u001b[0m | \u001b[0m16.84    \u001b[0m | \u001b[0m154.7    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.9849   \u001b[0m | \u001b[0m62.77    \u001b[0m | \u001b[0m2.598    \u001b[0m | \u001b[0m7.644    \u001b[0m | \u001b[0m121.6    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.9853   \u001b[0m | \u001b[0m87.29    \u001b[0m | \u001b[0m1.449    \u001b[0m | \u001b[0m4.814    \u001b[0m | \u001b[0m136.7    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.9836   \u001b[0m | \u001b[0m97.15    \u001b[0m | \u001b[0m1.015    \u001b[0m | \u001b[0m31.24    \u001b[0m | \u001b[0m136.8    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.9835   \u001b[0m | \u001b[0m87.41    \u001b[0m | \u001b[0m5.746    \u001b[0m | \u001b[0m4.877    \u001b[0m | \u001b[0m108.0    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.9833   \u001b[0m | \u001b[0m30.69    \u001b[0m | \u001b[0m1.563    \u001b[0m | \u001b[0m25.71    \u001b[0m | \u001b[0m110.7    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.9856   \u001b[0m | \u001b[0m79.55    \u001b[0m | \u001b[0m1.372    \u001b[0m | \u001b[0m3.881    \u001b[0m | \u001b[0m150.2    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.984    \u001b[0m | \u001b[0m97.29    \u001b[0m | \u001b[0m2.304    \u001b[0m | \u001b[0m18.7     \u001b[0m | \u001b[0m174.8    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.9811   \u001b[0m | \u001b[0m94.87    \u001b[0m | \u001b[0m2.003    \u001b[0m | \u001b[0m97.03    \u001b[0m | \u001b[0m770.3    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.9846   \u001b[0m | \u001b[0m21.03    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m2.466    \u001b[0m | \u001b[0m737.9    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.9805   \u001b[0m | \u001b[0m11.17    \u001b[0m | \u001b[0m13.67    \u001b[0m | \u001b[0m21.38    \u001b[0m | \u001b[0m760.4    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.9826   \u001b[0m | \u001b[0m38.89    \u001b[0m | \u001b[0m7.648    \u001b[0m | \u001b[0m2.236    \u001b[0m | \u001b[0m715.2    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.9853   \u001b[0m | \u001b[0m28.6     \u001b[0m | \u001b[0m1.896    \u001b[0m | \u001b[0m2.635    \u001b[0m | \u001b[0m138.0    \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.9856734097048669, 'params': {'max_depth': 77.32983850657278, 'min_samples_leaf': 2.9945638773827494, 'min_samples_split': 3.126668709295796, 'n_estimators': 224.4759742656425}}\n"
     ]
    }
   ],
   "source": [
    "rf_bo = BayesianOptimization(\n",
    "    f=bo_params_rf,\n",
    "    pbounds={\n",
    "        'n_estimators': (100, 1000),\n",
    "        'max_depth': (10, 100),\n",
    "        'min_samples_split': (2, 100),\n",
    "        'min_samples_leaf': (1, 50)\n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_bo.maximize(\n",
    "    n_iter=50,\n",
    "    init_points=2,\n",
    ")\n",
    "\n",
    "print(rf_bo.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5633dd4",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "423ad1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_score(xgb, X, y, n_fold):\n",
    "    X, y = X.values, y.values\n",
    "    strat_kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    roc_auc_list = []\n",
    "\n",
    "    for train_index, test_index in strat_kfold.split(X, y):\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        xgb.fit(x_train_fold, y_train_fold)\n",
    "        preds = xgb.predict(x_test_fold)\n",
    "        roc_auc_test = roc_auc_score(y_test_fold, preds)\n",
    "        roc_auc_list.append(roc_auc_test)\n",
    "\n",
    "    return np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "914add56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_params_xgb(n_estimators, max_depth, learning_rate, min_child_weight, subsample, colsample_bytree, gamma):\n",
    "    params = {\n",
    "        'n_estimators' : int(n_estimators),\n",
    "        'max_depth' : int(max_depth),\n",
    "        'learning_rate' : learning_rate,\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'subsample' : subsample,\n",
    "        'colsample_bytree' : colsample_bytree,\n",
    "        'gamma' : gamma,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    xgb = XGBClassifier(**params)\n",
    "    return stratified_kfold_score(xgb, X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e046d424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9885   \u001b[0m | \u001b[0m0.6873   \u001b[0m | \u001b[0m4.754    \u001b[0m | \u001b[0m0.2223   \u001b[0m | \u001b[0m7.191    \u001b[0m | \u001b[0m2.404    \u001b[0m | \u001b[0m240.4    \u001b[0m | \u001b[0m0.529    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9883   \u001b[0m | \u001b[0m0.9331   \u001b[0m | \u001b[0m3.006    \u001b[0m | \u001b[0m0.2153   \u001b[0m | \u001b[0m3.144    \u001b[0m | \u001b[0m9.729    \u001b[0m | \u001b[0m849.2    \u001b[0m | \u001b[0m0.6062   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9884   \u001b[0m | \u001b[0m0.9813   \u001b[0m | \u001b[0m4.18     \u001b[0m | \u001b[0m0.2118   \u001b[0m | \u001b[0m5.863    \u001b[0m | \u001b[0m2.56     \u001b[0m | \u001b[0m240.8    \u001b[0m | \u001b[0m0.6251   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9862   \u001b[0m | \u001b[0m0.7316   \u001b[0m | \u001b[0m4.132    \u001b[0m | \u001b[0m0.01213  \u001b[0m | \u001b[0m7.498    \u001b[0m | \u001b[0m3.51     \u001b[0m | \u001b[0m240.7    \u001b[0m | \u001b[0m0.8691   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.988    \u001b[0m | \u001b[0m0.7128   \u001b[0m | \u001b[0m1.704    \u001b[0m | \u001b[0m0.2724   \u001b[0m | \u001b[0m6.308    \u001b[0m | \u001b[0m9.484    \u001b[0m | \u001b[0m367.5    \u001b[0m | \u001b[0m0.8402   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9875   \u001b[0m | \u001b[0m0.9993   \u001b[0m | \u001b[0m0.2558   \u001b[0m | \u001b[0m0.2369   \u001b[0m | \u001b[0m8.196    \u001b[0m | \u001b[0m8.131    \u001b[0m | \u001b[0m414.4    \u001b[0m | \u001b[0m0.7322   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9877   \u001b[0m | \u001b[0m0.778    \u001b[0m | \u001b[0m4.519    \u001b[0m | \u001b[0m0.2019   \u001b[0m | \u001b[0m4.614    \u001b[0m | \u001b[0m9.695    \u001b[0m | \u001b[0m456.5    \u001b[0m | \u001b[0m0.5138   \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.9894   \u001b[0m | \u001b[95m0.8863   \u001b[0m | \u001b[95m4.863    \u001b[0m | \u001b[95m0.06915  \u001b[0m | \u001b[95m5.042    \u001b[0m | \u001b[95m2.813    \u001b[0m | \u001b[95m241.1    \u001b[0m | \u001b[95m0.8708   \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.9895   \u001b[0m | \u001b[95m0.8497   \u001b[0m | \u001b[95m3.935    \u001b[0m | \u001b[95m0.07509  \u001b[0m | \u001b[95m7.215    \u001b[0m | \u001b[95m1.702    \u001b[0m | \u001b[95m240.3    \u001b[0m | \u001b[95m0.9714   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9888   \u001b[0m | \u001b[0m0.7783   \u001b[0m | \u001b[0m4.004    \u001b[0m | \u001b[0m0.1628   \u001b[0m | \u001b[0m7.877    \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m239.7    \u001b[0m | \u001b[0m0.7912   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9888   \u001b[0m | \u001b[0m0.8278   \u001b[0m | \u001b[0m3.612    \u001b[0m | \u001b[0m0.1479   \u001b[0m | \u001b[0m6.585    \u001b[0m | \u001b[0m2.155    \u001b[0m | \u001b[0m239.6    \u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9883   \u001b[0m | \u001b[0m0.9852   \u001b[0m | \u001b[0m2.557    \u001b[0m | \u001b[0m0.1856   \u001b[0m | \u001b[0m6.166    \u001b[0m | \u001b[0m1.273    \u001b[0m | \u001b[0m240.1    \u001b[0m | \u001b[0m0.9505   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.9892   \u001b[0m | \u001b[0m0.9672   \u001b[0m | \u001b[0m4.235    \u001b[0m | \u001b[0m0.08758  \u001b[0m | \u001b[0m6.529    \u001b[0m | \u001b[0m1.399    \u001b[0m | \u001b[0m238.8    \u001b[0m | \u001b[0m0.7944   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.9116   \u001b[0m | \u001b[0m3.968    \u001b[0m | \u001b[0m0.2173   \u001b[0m | \u001b[0m6.033    \u001b[0m | \u001b[0m1.076    \u001b[0m | \u001b[0m239.3    \u001b[0m | \u001b[0m0.784    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9893   \u001b[0m | \u001b[0m0.8657   \u001b[0m | \u001b[0m4.196    \u001b[0m | \u001b[0m0.1741   \u001b[0m | \u001b[0m4.286    \u001b[0m | \u001b[0m2.308    \u001b[0m | \u001b[0m241.2    \u001b[0m | \u001b[0m0.9168   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.988    \u001b[0m | \u001b[0m0.5091   \u001b[0m | \u001b[0m4.847    \u001b[0m | \u001b[0m0.07155  \u001b[0m | \u001b[0m3.939    \u001b[0m | \u001b[0m2.159    \u001b[0m | \u001b[0m241.6    \u001b[0m | \u001b[0m0.5752   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9894   \u001b[0m | \u001b[0m0.5833   \u001b[0m | \u001b[0m4.83     \u001b[0m | \u001b[0m0.0454   \u001b[0m | \u001b[0m5.367    \u001b[0m | \u001b[0m2.246    \u001b[0m | \u001b[0m240.3    \u001b[0m | \u001b[0m0.5742   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.988    \u001b[0m | \u001b[0m0.7415   \u001b[0m | \u001b[0m3.197    \u001b[0m | \u001b[0m0.1965   \u001b[0m | \u001b[0m7.536    \u001b[0m | \u001b[0m1.339    \u001b[0m | \u001b[0m240.3    \u001b[0m | \u001b[0m0.7624   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.7554   \u001b[0m | \u001b[0m4.196    \u001b[0m | \u001b[0m0.1166   \u001b[0m | \u001b[0m4.418    \u001b[0m | \u001b[0m3.041    \u001b[0m | \u001b[0m241.8    \u001b[0m | \u001b[0m0.8479   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9887   \u001b[0m | \u001b[0m0.7924   \u001b[0m | \u001b[0m4.239    \u001b[0m | \u001b[0m0.1693   \u001b[0m | \u001b[0m6.027    \u001b[0m | \u001b[0m2.323    \u001b[0m | \u001b[0m238.5    \u001b[0m | \u001b[0m0.6367   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9887   \u001b[0m | \u001b[0m0.919    \u001b[0m | \u001b[0m2.963    \u001b[0m | \u001b[0m0.1185   \u001b[0m | \u001b[0m4.949    \u001b[0m | \u001b[0m9.874    \u001b[0m | \u001b[0m475.9    \u001b[0m | \u001b[0m0.877    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.9888   \u001b[0m | \u001b[0m0.6645   \u001b[0m | \u001b[0m3.617    \u001b[0m | \u001b[0m0.1094   \u001b[0m | \u001b[0m7.266    \u001b[0m | \u001b[0m7.68     \u001b[0m | \u001b[0m120.6    \u001b[0m | \u001b[0m0.5986   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.9869   \u001b[0m | \u001b[0m0.7018   \u001b[0m | \u001b[0m3.334    \u001b[0m | \u001b[0m0.2991   \u001b[0m | \u001b[0m6.813    \u001b[0m | \u001b[0m2.819    \u001b[0m | \u001b[0m807.9    \u001b[0m | \u001b[0m0.6588   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.9909   \u001b[0m | \u001b[0m4.383    \u001b[0m | \u001b[0m0.1962   \u001b[0m | \u001b[0m4.098    \u001b[0m | \u001b[0m2.05     \u001b[0m | \u001b[0m239.8    \u001b[0m | \u001b[0m0.621    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.9885   \u001b[0m | \u001b[0m0.7076   \u001b[0m | \u001b[0m4.223    \u001b[0m | \u001b[0m0.05705  \u001b[0m | \u001b[0m6.808    \u001b[0m | \u001b[0m1.682    \u001b[0m | \u001b[0m237.3    \u001b[0m | \u001b[0m0.9862   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.9881   \u001b[0m | \u001b[0m0.9061   \u001b[0m | \u001b[0m3.539    \u001b[0m | \u001b[0m0.1929   \u001b[0m | \u001b[0m4.782    \u001b[0m | \u001b[0m2.863    \u001b[0m | \u001b[0m241.2    \u001b[0m | \u001b[0m0.5622   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.9884   \u001b[0m | \u001b[0m0.5848   \u001b[0m | \u001b[0m4.642    \u001b[0m | \u001b[0m0.1786   \u001b[0m | \u001b[0m6.995    \u001b[0m | \u001b[0m1.597    \u001b[0m | \u001b[0m240.6    \u001b[0m | \u001b[0m0.9324   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.967    \u001b[0m | \u001b[0m3.442    \u001b[0m | \u001b[0m0.203    \u001b[0m | \u001b[0m8.993    \u001b[0m | \u001b[0m3.946    \u001b[0m | \u001b[0m101.6    \u001b[0m | \u001b[0m0.8237   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.9882   \u001b[0m | \u001b[0m0.6118   \u001b[0m | \u001b[0m2.08     \u001b[0m | \u001b[0m0.209    \u001b[0m | \u001b[0m6.304    \u001b[0m | \u001b[0m5.846    \u001b[0m | \u001b[0m270.2    \u001b[0m | \u001b[0m0.8936   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.9895   \u001b[0m | \u001b[0m0.7151   \u001b[0m | \u001b[0m3.878    \u001b[0m | \u001b[0m0.213    \u001b[0m | \u001b[0m8.596    \u001b[0m | \u001b[0m3.318    \u001b[0m | \u001b[0m102.3    \u001b[0m | \u001b[0m0.9773   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.9893   \u001b[0m | \u001b[0m0.741    \u001b[0m | \u001b[0m4.898    \u001b[0m | \u001b[0m0.2247   \u001b[0m | \u001b[0m8.174    \u001b[0m | \u001b[0m9.396    \u001b[0m | \u001b[0m530.2    \u001b[0m | \u001b[0m0.9196   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.8315   \u001b[0m | \u001b[0m3.215    \u001b[0m | \u001b[0m0.2781   \u001b[0m | \u001b[0m6.175    \u001b[0m | \u001b[0m6.91     \u001b[0m | \u001b[0m477.4    \u001b[0m | \u001b[0m0.9232   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.9881   \u001b[0m | \u001b[0m0.6372   \u001b[0m | \u001b[0m3.959    \u001b[0m | \u001b[0m0.248    \u001b[0m | \u001b[0m9.836    \u001b[0m | \u001b[0m2.199    \u001b[0m | \u001b[0m344.9    \u001b[0m | \u001b[0m0.7093   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.9887   \u001b[0m | \u001b[0m0.9312   \u001b[0m | \u001b[0m3.535    \u001b[0m | \u001b[0m0.05627  \u001b[0m | \u001b[0m8.187    \u001b[0m | \u001b[0m6.937    \u001b[0m | \u001b[0m391.2    \u001b[0m | \u001b[0m0.5176   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.9885   \u001b[0m | \u001b[0m0.5207   \u001b[0m | \u001b[0m4.61     \u001b[0m | \u001b[0m0.112    \u001b[0m | \u001b[0m5.098    \u001b[0m | \u001b[0m4.207    \u001b[0m | \u001b[0m281.9    \u001b[0m | \u001b[0m0.9082   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.9867   \u001b[0m | \u001b[0m0.8468   \u001b[0m | \u001b[0m0.9554   \u001b[0m | \u001b[0m0.1165   \u001b[0m | \u001b[0m9.061    \u001b[0m | \u001b[0m1.606    \u001b[0m | \u001b[0m523.9    \u001b[0m | \u001b[0m0.5915   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.987    \u001b[0m | \u001b[0m0.5225   \u001b[0m | \u001b[0m0.7684   \u001b[0m | \u001b[0m0.1369   \u001b[0m | \u001b[0m7.458    \u001b[0m | \u001b[0m2.119    \u001b[0m | \u001b[0m321.5    \u001b[0m | \u001b[0m0.529    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.7562   \u001b[0m | \u001b[0m4.404    \u001b[0m | \u001b[0m0.1849   \u001b[0m | \u001b[0m6.465    \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m238.8    \u001b[0m | \u001b[0m0.6714   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.5984   \u001b[0m | \u001b[0m4.334    \u001b[0m | \u001b[0m0.05308  \u001b[0m | \u001b[0m7.606    \u001b[0m | \u001b[0m8.683    \u001b[0m | \u001b[0m530.3    \u001b[0m | \u001b[0m0.9572   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.9895   \u001b[0m | \u001b[0m0.6959   \u001b[0m | \u001b[0m4.312    \u001b[0m | \u001b[0m0.1647   \u001b[0m | \u001b[0m9.103    \u001b[0m | \u001b[0m3.24     \u001b[0m | \u001b[0m102.0    \u001b[0m | \u001b[0m0.6371   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.9885   \u001b[0m | \u001b[0m0.6145   \u001b[0m | \u001b[0m4.324    \u001b[0m | \u001b[0m0.2607   \u001b[0m | \u001b[0m8.061    \u001b[0m | \u001b[0m9.253    \u001b[0m | \u001b[0m528.7    \u001b[0m | \u001b[0m0.5751   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.9399   \u001b[0m | \u001b[0m4.648    \u001b[0m | \u001b[0m0.08803  \u001b[0m | \u001b[0m8.383    \u001b[0m | \u001b[0m9.562    \u001b[0m | \u001b[0m531.1    \u001b[0m | \u001b[0m0.8013   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.9518   \u001b[0m | \u001b[0m4.058    \u001b[0m | \u001b[0m0.1586   \u001b[0m | \u001b[0m8.785    \u001b[0m | \u001b[0m3.065    \u001b[0m | \u001b[0m103.8    \u001b[0m | \u001b[0m0.9106   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.9884   \u001b[0m | \u001b[0m0.6687   \u001b[0m | \u001b[0m3.137    \u001b[0m | \u001b[0m0.2088   \u001b[0m | \u001b[0m8.814    \u001b[0m | \u001b[0m2.313    \u001b[0m | \u001b[0m103.5    \u001b[0m | \u001b[0m0.5401   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.9863   \u001b[0m | \u001b[0m0.7275   \u001b[0m | \u001b[0m3.345    \u001b[0m | \u001b[0m0.03186  \u001b[0m | \u001b[0m8.745    \u001b[0m | \u001b[0m2.843    \u001b[0m | \u001b[0m101.5    \u001b[0m | \u001b[0m0.6912   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.9894   \u001b[0m | \u001b[0m0.8935   \u001b[0m | \u001b[0m4.451    \u001b[0m | \u001b[0m0.1475   \u001b[0m | \u001b[0m6.713    \u001b[0m | \u001b[0m1.595    \u001b[0m | \u001b[0m239.9    \u001b[0m | \u001b[0m0.846    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.9888   \u001b[0m | \u001b[0m0.9163   \u001b[0m | \u001b[0m4.467    \u001b[0m | \u001b[0m0.2813   \u001b[0m | \u001b[0m4.383    \u001b[0m | \u001b[0m1.977    \u001b[0m | \u001b[0m240.6    \u001b[0m | \u001b[0m0.6545   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m0.7652   \u001b[0m | \u001b[0m3.152    \u001b[0m | \u001b[0m0.297    \u001b[0m | \u001b[0m4.895    \u001b[0m | \u001b[0m6.994    \u001b[0m | \u001b[0m844.5    \u001b[0m | \u001b[0m0.795    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.9893   \u001b[0m | \u001b[0m0.854    \u001b[0m | \u001b[0m3.922    \u001b[0m | \u001b[0m0.1702   \u001b[0m | \u001b[0m6.744    \u001b[0m | \u001b[0m6.088    \u001b[0m | \u001b[0m586.3    \u001b[0m | \u001b[0m0.8601   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.989    \u001b[0m | \u001b[0m0.9675   \u001b[0m | \u001b[0m4.783    \u001b[0m | \u001b[0m0.1357   \u001b[0m | \u001b[0m4.201    \u001b[0m | \u001b[0m9.105    \u001b[0m | \u001b[0m900.4    \u001b[0m | \u001b[0m0.7572   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.8639   \u001b[0m | \u001b[0m2.482    \u001b[0m | \u001b[0m0.156    \u001b[0m | \u001b[0m8.509    \u001b[0m | \u001b[0m2.655    \u001b[0m | \u001b[0m184.8    \u001b[0m | \u001b[0m0.6394   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.9885   \u001b[0m | \u001b[0m0.6374   \u001b[0m | \u001b[0m3.35     \u001b[0m | \u001b[0m0.1933   \u001b[0m | \u001b[0m4.483    \u001b[0m | \u001b[0m3.83     \u001b[0m | \u001b[0m398.4    \u001b[0m | \u001b[0m0.6337   \u001b[0m |\n",
      "=============================================================================================================\n",
      "{'target': 0.9894828211065727, 'params': {'colsample_bytree': 0.8497054793943353, 'gamma': 3.935081236491979, 'learning_rate': 0.07509368737832518, 'max_depth': 7.215329530514387, 'min_child_weight': 1.7019371790152105, 'n_estimators': 240.30115793246688, 'subsample': 0.971358258121751}}\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(\n",
    "    f=bo_params_xgb,\n",
    "    pbounds={\n",
    "        'n_estimators': (100, 1000),\n",
    "        'max_depth': (3, 10),\n",
    "        'learning_rate' : (0.01, 0.3),\n",
    "        'min_child_weight' : (1, 10),\n",
    "        'subsample' : (0.5, 1.0),\n",
    "        'colsample_bytree' : (0.5, 1.0),\n",
    "        'gamma' : (0, 5)\n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb_bo.maximize(\n",
    "    n_iter=50,\n",
    "    init_points=2,\n",
    ")\n",
    "\n",
    "print(xgb_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa53738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
